# Writereader AI Equivalence Experiment
# Switch between GPU and CPU configurations by commenting/uncommenting sections

services:
  wr-ml-service:
    image: frederikjwritereader/atel:experiment
    ports: 
      - "5001:5000"
    volumes:
      - ./models/new_modeldirv4_atel:/modeldir
    environment:
      - MODEL_DIRECTORY=/modeldir
      - INITIAL_MODEL=llama_full
      
      # === GPU Configuration (for Datacrunch/Linux with NVIDIA GPU) ===
      # Uncomment these lines for GPU deployment:
      - MODEL_DEVICE=cuda
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
      
      # === CPU Configuration (for Mac/testing) ===
      # Comment out this line for GPU deployment:
      # - MODEL_DEVICE=cpu
      
    networks:
      - ml-network
    restart: unless-stopped

  automaticscore:
    image: frederikjwritereader/automaticscore:experiment
    ports:
      - "5002:5000"
    volumes:
      - ./models/autoscoring_v2:/modeldir
    environment:
      - MODEL_DIRECTORY=/modeldir
      - MODEL_DETECT_NOISE=detect_noise/logistic_classifier/model
      - MODEL_EVALUATE_TEXT=evaluate_text/simple
      - API_TEXT_PROPOSAL=http://wr-ml-service:5000/api/textproposal/
      - THRESHOLD_EVALUATE_TEXT=2.0  # Optimized for experiment
      - THRESHOLD_DENOISE=0.5
    depends_on:
      - wr-ml-service
    networks:
      - ml-network
    restart: unless-stopped

networks:
  ml-network:
    driver: bridge